While technology to read facial expressions could potentially provide insights, its use to monitor students risks invasion of privacy and unfair judgment.  On one hand, the Facial Action Coding System aims to give insight into students engagement and comprehension, insights that could help educators improve. However, facial expressions do not always reflect inner thoughts and emotions accurately. A thoughtful student may appear disengaged while deeply considering complex ideas. Likewise, a student struggling to understand may smile and nod to avoid drawing attention rather than from genuine comprehension. Judging students based only on external expressions risks misinterpreting their experiences and unfairly impacting their education. It could make some students feel constantly monitored and uncomfortable naturally expressing a range of emotions. Especially for students still learning to regulate expressions, constant monitoring may stress rather than help them. Teachers aim to understand each student as a whole person rather than make determinations based on a single data point. Student-teacher relationships built on trust and open dialogue are better for learning than invasive technology. While facial recognition aims to provide data, truly understanding learning requires seeing the full complexity and context of each human experience, which technology alone cannot replace. In summary, while the intentions of technologies like facial analysis are to help education, their use to constantly monitor students risks unintended consequences and fails to account for the rich complexity of human learning experiences. The social-emotional well-being of students should be the priority, and that is best supported through caring human relationships rather than invasive forms of monitoring.